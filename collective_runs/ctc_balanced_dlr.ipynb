{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctc_utils.functions import def_gen_expr_for_datasets, def_labels_for_datasets, load_data, prune_training_set, loopForDLR, unsupervisedClusteringFaiss\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from classifiers.DTC import dtc\n",
    "from classifiers.LogisticRegression import logreg\n",
    "from classifiers.LinearSVC import lsvc\n",
    "from classifiers.kNN import knn\n",
    "from classifiers.MLP import mlp\n",
    "from classifiers.NB import gnb\n",
    "from classifiers.SDGC import sdg\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import  Counter\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine datasets from different protocols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "cell_names, gene_names, labels, gene_expr_bin = load_data()\n",
    "\n",
    "#Training datasets\n",
    "training_datasets = [gene_expr_bin[6444:23153],\n",
    " np.concatenate((gene_expr_bin[0:6443], gene_expr_bin[6697:23153])), \n",
    " np.concatenate((gene_expr_bin[0:6696], gene_expr_bin[9919:23153])),\n",
    " np.concatenate((gene_expr_bin[0:9918], gene_expr_bin[10172:23153])),\n",
    " np.concatenate((gene_expr_bin[0:10171], gene_expr_bin[13394:23153])), \n",
    " np.concatenate((gene_expr_bin[0:13393], gene_expr_bin[16616:23153])),\n",
    " np.concatenate((gene_expr_bin[0:16615], gene_expr_bin[19792:23153])),\n",
    " gene_expr_bin[0:19791]    \n",
    " ]\n",
    "\n",
    "# Test Datasets\n",
    "# [ge_10xv2, ge_SM2, ge_10xv3, ge_CL, ge_DR, ge_iD, ge_SW, ge_10xv2_2]\n",
    "test_datasets = def_gen_expr_for_datasets(gene_expr_bin)\n",
    "\n",
    "\n",
    "labels_for__training_datasets = [labels[6444:23153],\n",
    " np.concatenate((labels[0:6443], labels[6697:23153])), \n",
    " np.concatenate((labels[0:6696], labels[9919:23153])),\n",
    " np.concatenate((labels[0:9918], labels[10172:23153])),\n",
    " np.concatenate((labels[0:10171], labels[13394:23153])), \n",
    " np.concatenate((labels[0:13393], labels[16616:23153])),\n",
    " np.concatenate((labels[0:16615], labels[19792:23153])),\n",
    " labels[0:19791]    \n",
    " ]\n",
    "\n",
    "# Labels for test datasets\n",
    "# [lb_10xv2, lb_SM2, lb_10xv3, lb_CL, lb_DR, lb_iD, lb_SW, lb_10xv2_2]\n",
    "labels_for_test_datasets = def_labels_for_datasets(labels)\n",
    "\n",
    "\n",
    "acc_matrix = np.zeros(7)\n",
    "\n",
    "all_matrix = np.zeros(shape = (8,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Uncommend commented part to balance the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x_train in enumerate(training_datasets):\n",
    "    \n",
    "    y_train = labels_for__training_datasets[i]\n",
    "    x_test = test_datasets[i]\n",
    "    y_test = labels_for_test_datasets[i]\n",
    "\n",
    "    ###########################################################################################\n",
    "    # Fix imbalance\n",
    "    # Find out the majority class and its occurances\n",
    "    # d = Counter(y_train)\n",
    "    # max_occurances = max(d, key=d. get)\n",
    "    # max_num = d.get(max_occurances)\n",
    "    # half = int(max_num/2)\n",
    "\n",
    "    # Eliminate all classes to the hald of the majority class\n",
    "    # x_train, y_train = prune_training_set(x_train, y_train, 3158)\n",
    "\n",
    "    # Feature selection\n",
    "    sel = VarianceThreshold(threshold=0.16)\n",
    "    x_train = sel.fit_transform(x_train)\n",
    "    x_test = sel.transform(x_test)\n",
    "\n",
    "    # unsupervised clustering using faiss \n",
    "    neighbors_index_ps, neighbors_index_ps_test, x_train, x_test = unsupervisedClusteringFaiss(x_train, x_test, 16)\n",
    "    # calculate DLR for each cell sample for training of the model.\n",
    "    x_train = loopForDLR(neighbors_index_ps, x_train)\n",
    "    # calculate DLR for each cell sample for testing the  model.\n",
    "    x_test = loopForDLR(neighbors_index_ps_test, x_train)\n",
    "\n",
    "    #  # Apply oversampling\n",
    "    # over_sampling = RandomOverSampler(sampling_strategy = \"not majority\")\n",
    "    # # fit and apply the transform\n",
    "    # x_train, y_train = over_sampling.fit_resample(x_train, y_train)\n",
    "\n",
    "   ############################################################################################### \n",
    "    print(\"classification...\")    \n",
    "\n",
    "    #Apply knn\n",
    "    model, acc_knn = knn(x_train, y_train, x_test,y_test)\n",
    "\n",
    "    #Apply logistic regression\n",
    "    model, acc_logreg = logreg(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    #Apply Decision Tree Classifier\n",
    "    model, acc_dtc = dtc(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    #Apply LinearSVC Classifier\n",
    "    model, acc_lsvc = lsvc(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    #Apply MLP\n",
    "    model, acc_mlp = mlp(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    #Apply GaussianNB\n",
    "    model, acc_gnb = gnb(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    #Apply SDGC\n",
    "    model, acc_sdg = sdg(x_train, y_train, x_test, y_test)\n",
    "    #contains_all accuracy\n",
    "    all_acc_within_dataset = np.array([acc_knn, acc_logreg, acc_dtc, acc_lsvc, acc_mlp, acc_gnb, acc_sdg])\n",
    "\n",
    "    acc_matrix = all_acc_within_dataset\n",
    "\n",
    "    all_matrix[i] = acc_matrix\n",
    "    print(all_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results matrix to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../results/performance_matrices/ctc_dlr_non_balanced\", all_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load results matrix from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matrix = np.load(\"../results/performance_matrices/ctc_dlr_non_balanced.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "y_labels = [\"excl_10xv2\", \"excl_SM2\", \"excl_10xv3\", \"excl_CL\", \"excl_DR\", \"excl_iD\", \"excl_SW\", \"excl_10xv2_2\"]\n",
    "x_labels = [\"knn\", \"Logistic Regression\", \"DTC\", \"LinearSVC\", \"MLP\", \"GaussianNB\", \"SDG\" ]\n",
    "\n",
    "ax = sns.heatmap(all_matrix, annot=True, fmt=\".2f\")  \n",
    "# labels, title and ticks\n",
    "ax.xaxis.set_ticklabels(x_labels, rotation = 90, fontsize = 6)\n",
    "ax.yaxis.set_ticklabels(y_labels, rotation = 0)\n",
    "\n",
    "plt.savefig(\"../report_pdf_results/ctc_dlr_non_balanced.pdf\", format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(all_matrix, labels = x_labels)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(all_matrix.T, labels = y_labels)\n",
    "plt.xticks(rotation=90)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
